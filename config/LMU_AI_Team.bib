
@article{chilamkurthy_etal18,
	title = {Deep learning algorithms for detection of critical findings in head {CT} scans: a retrospective study},
	volume = {392},
	issn = {01406736},
	shorttitle = {Deep learning algorithms for detection of critical findings in head {CT} scans},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0140673618316453},
	doi = {10.1016/S0140-6736(18)31645-3},
	language = {en},
	number = {10162},
	urldate = {2021-10-29},
	journal = {The Lancet},
	author = {Chilamkurthy, Sasank and Ghosh, Rohit and Tanamala, Swetha and Biviji, Mustafa and Campeau, Norbert G and Venugopal, Vasantha Kumar and Mahajan, Vidur and Rao, Pooja and Warier, Prashant},
	month = dec,
	year = {2018},
	pages = {2388--2396},
	file = {(Chilamkurthy et al. 2018).pdf:/Users/anne/Zotero/storage/9SUI8XJ3/(Chilamkurthy et al. 2018).pdf:application/pdf},
}

@article{oneill_etal21,
	title = {Active {Reprioritization} of the {Reading} {Worklist} {Using} {Artificial}                     {Intelligence} {Has} a {Beneficial} {Effect} on the {Turnaround} {Time} for {Interpretation}                     of {Head} {CT} with {Intracranial} {Hemorrhage}},
	volume = {3},
	url = {https://pubs.rsna.org/doi/10.1148/ryai.2020200024},
	doi = {10.1148/ryai.2020200024},
	abstract = {PurposeTo determine how to optimize the delivery of machine learning techniques                             in a clinical setting to detect intracranial hemorrhage (ICH) on                             non–contrast-enhanced CT images to radiologists to improve                             workflow.Materials and MethodsIn this study, a commercially available machine learning algorithm that                             flags abnormal noncontrast CT examinations for ICH was implemented in a                             busy academic neuroradiology practice between September 2017 and March                             2019. The algorithm was introduced in three phases: (a)                             as a “pop-up” widget on ancillary monitors,                                 (b) as a marked examination in reading worklists,                             and (c) as a marked examination for reprioritization                             based on the presence of the flag. A statistical approach, which was                             based on a queuing theory, was implemented to assess the impact of each                             intervention on queue-adjusted wait and turnaround time compared with                             historical controls.ResultsNotification with a widget or flagging the examination had no effect on                             queue-adjusted image wait (P {\textgreater} .99) or turnaround                             time (P = .6). However, a reduction in                             queue-adjusted wait time was observed between negative (15.45 minutes;                             95\% CI: 15.07, 15.38) and positive (12.02 minutes; 95\% CI: 11.06, 12.97;                                 P {\textless} .0001) artificial                             intelligence–detected ICH examinations with reprioritization.                             Reduced wait time was present for all order classes but was greatest for                             examinations ordered as routine for both inpatients and outpatients                             because of their low priority.ConclusionThe approach used to present flags from artificial intelligence and                             machine learning algorithms to the radiologist can reduce image wait                             time and turnaround times.Keywords: Emergency Radiology,                                                           Informatics,                              Technology Assessment                         © RSNA, 2021See also the commentary by O’Connor and Bhalla in this issue.},
	number = {2},
	urldate = {2021-10-29},
	journal = {Radiology: Artificial Intelligence},
	author = {O’Neill, Thomas                             J. and Xi, Yin and Stehel, Edward and Browning, Travis and Ng, Yee                         Seng and Baker, Chris and Peshock, Ronald                             M.},
	month = mar,
	year = {2021},
	pages = {e200024},
	annote = {Results:
Notification with a widget or flagging the examination had no effect on queue-adjusted image wait (P {\textgreater} .99) or turnaround time (P = .6). However, a reduction in queue-adjusted wait time was observed between negative (15.45 minutes; 95\% CI: 15.07, 15.38) and positive (12.02 minutes; 95\% CI: 11.06, 12.97; P {\textless} .0001) artificial intelligence–detected ICH examinations with reprioritization. Reduced wait time was present for all order classes but was greatest for examinations ordered as routine for both inpatients and outpatients because of their low priority.},
	file = {(O’Neill et al., 2020).pdf:/Users/anne/Zotero/storage/HJG5U5HD/(O’Neill et al., 2020).pdf:application/pdf},
}

@article{mclouth_etal21,
	title = {Validation of a {Deep} {Learning} {Tool} in the {Detection} of {Intracranial} {Hemorrhage} and {Large} {Vessel} {Occlusion}},
	volume = {12},
	issn = {1664-2295},
	url = {https://www.frontiersin.org/article/10.3389/fneur.2021.656112},
	doi = {10.3389/fneur.2021.656112},
	abstract = {Purpose: Recently developed machine-learning algorithms have demonstrated strong performance in the detection of intracranial hemorrhage (ICH) and large vessel occlusion (LVO). However, their generalizability is often limited by geographic bias of studies. The aim of this study was to validate a commercially available deep learning-based tool in the detection of both ICH and LVO across multiple hospital sites and vendors throughout the U.S.Materials and Methods: This was a retrospective and multicenter study using anonymized data from two institutions. Eight hundred fourteen non-contrast CT cases and 378 CT angiography cases were analyzed to evaluate ICH and LVO, respectively. The tool's ability to detect and quantify ICH, LVO, and their various subtypes was assessed among multiple CT vendors and hospitals across the United States. Ground truth was based off imaging interpretations from two board-certified neuroradiologists.Results: There were 255 positive and 559 negative ICH cases. Accuracy was 95.6\%, sensitivity was 91.4\%, and specificity was 97.5\% for the ICH tool. ICH was further stratified into the following subtypes: intraparenchymal, intraventricular, epidural/subdural, and subarachnoid with true positive rates of 92.9, 100, 94.3, and 89.9\%, respectively. ICH true positive rates by volume [small ({\textless}5 mL), medium (5–25 mL), and large ({\textgreater}25 mL)] were 71.8, 100, and 100\%, respectively. There were 156 positive and 222 negative LVO cases. The LVO tool demonstrated an accuracy of 98.1\%, sensitivity of 98.1\%, and specificity of 98.2\%. A subset of 55 randomly selected cases were also assessed for LVO detection at various sites, including the distal internal carotid artery, middle cerebral artery M1 segment, proximal middle cerebral artery M2 segment, and distal middle cerebral artery M2 segment with an accuracy of 97.0\%, sensitivity of 94.3\%, and specificity of 97.4\%.Conclusion: Deep learning tools can be effective in the detection of both ICH and LVO across a wide variety of hospital systems. While some limitations were identified, specifically in the detection of small ICH and distal M2 occlusion, this study highlights a deep learning tool that can assist radiologists in the detection of emergent findings in a variety of practice settings.},
	urldate = {2021-10-29},
	journal = {Frontiers in Neurology},
	author = {McLouth, Joel and Elstrott, Sebastian and Chaibi, Yasmina and Quenet, Sarah and Chang, Peter D. and Chow, Daniel S. and Soun, Jennifer E.},
	year = {2021},
	pages = {655},
	file = {(McLouth et al., 2021).pdf:/Users/anne/Zotero/storage/UAPI23I9/(McLouth et al., 2021).pdf:application/pdf},
}

@article{rava_etal21,
	title = {Assessment of an {Artificial} {Intelligence} {Algorithm} for {Detection} of {Intracranial} {Hemorrhage}},
	volume = {150},
	issn = {18788750},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1878875021003272},
	doi = {10.1016/j.wneu.2021.02.134},
	language = {en},
	urldate = {2021-10-29},
	journal = {World Neurosurgery},
	author = {Rava, Ryan A. and Seymour, Samantha E. and LaQue, Meredith E. and Peterson, Blake A. and Snyder, Kenneth V. and Mokin, Maxim and Waqas, Muhammad and Hoi, Yiemeng and Davies, Jason M. and Levy, Elad I. and Siddiqui, Adnan H. and Ionita, Ciprian N.},
	month = jun,
	year = {2021},
	pages = {e209--e217},
	file = {(Rava et al., 2021).pdf:/Users/anne/Zotero/storage/B32NPIX8/(Rava et al., 2021).pdf:application/pdf},
}

@article{lee_etal19,
	title = {An explainable deep-learning algorithm for the detection of acute intracranial haemorrhage from small datasets},
	volume = {3},
	copyright = {2018 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2157-846X},
	url = {https://www.nature.com/articles/s41551-018-0324-9},
	doi = {10.1038/s41551-018-0324-9},
	abstract = {Owing to improvements in image recognition via deep learning, machine-learning algorithms could eventually be applied to automated medical diagnoses that can guide clinical decision-making. However, these algorithms remain a ‘black box’ in terms of how they generate the predictions from the input data. Also, high-performance deep learning requires large, high-quality training datasets. Here, we report the development of an understandable deep-learning system that detects acute intracranial haemorrhage (ICH) and classifies five ICH subtypes from unenhanced head computed-tomography scans. By using a dataset of only 904 cases for algorithm training, the system achieved a performance similar to that of expert radiologists in two independent test datasets containing 200 cases (sensitivity of 98\% and specificity of 95\%) and 196 cases (sensitivity of 92\% and specificity of 95\%). The system includes an attention map and a prediction basis retrieved from training data to enhance explainability, and an iterative process that mimics the workflow of radiologists. Our approach to algorithm development can facilitate the development of deep-learning systems for a variety of clinical applications and accelerate their adoption into clinical practice.},
	language = {en},
	number = {3},
	urldate = {2021-10-29},
	journal = {Nature Biomedical Engineering},
	author = {Lee, Hyunkwang and Yune, Sehyo and Mansouri, Mohammad and Kim, Myeongchan and Tajmir, Shahein H. and Guerrier, Claude E. and Ebert, Sarah A. and Pomerantz, Stuart R. and Romero, Javier M. and Kamalian, Shahmir and Gonzalez, Ramon G. and Lev, Michael H. and Do, Synho},
	month = mar,
	year = {2019},
	pages = {173--182},
	file = {(Lee et al., 2019).pdf:/Users/anne/Zotero/storage/K3TAR5TU/(Lee et al., 2019).pdf:application/pdf},
}

@techreport{faes_etal19,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Deep {Learning} {Under} {Scrutiny}: {Performance} {Against} {Health} {Care} {Professionals} in {Detecting} {Diseases} from {Medical} {Imaging} - {Systematic} {Review} and {Meta}-{Analysis}},
	shorttitle = {Deep {Learning} {Under} {Scrutiny}},
	url = {https://papers.ssrn.com/abstract=3384923},
	abstract = {Background: Deep learning offers considerable promise for medical diagnostics. In this review, we evaluated the diagnostic accuracy of deep learning (DL) algorithms versus health care professionals (HCPs) in classifying diseases from medical imaging.      Methods: We searched (Pre-)Medline, Embase, Science Citation Index, Conference Proceedings Citation Index, and arXiv from 01 January 2012 until 31 May 2018. Studies comparing the diagnostic performance of DL models and HCPs, for any pre-specified condition based on medical imaging material, were included. We extracted binary diagnostic accuracy data and constructed contingency tables at the reported thresholds to derive the outcomes of interest: sensitivity and specificity. Studies undertaking an out-of-sample validation were included in a meta-analysis.      Results: 24 studies, from a starting number of 19889, compared DL models with HCPs. 22 studies provided enough data to construct contingency tables, enabling calculation of test accuracy. The mean sensitivity for DL models was 78\% (range 13 - 100\%), and mean specificity was 86\% (range 51 - 100\%). An out-of-sample external validation was performed by 5 studies and were therefore included in the meta-analysis. We found a pooled sensitivity of 86\% (95\% CI: 84 - 88\%) for DL models and 93\% (95\% CI: 87 - 97\%) for HCPs, and a pooled specificity of 88\% (95\% CI: 84 - 92\%) for DL models and 87\% (95\% CI: 84 - 89\%) for HCPs.     Conclusion: Our review found the diagnostic performance of deep learning models to be similar to health care professionals. A major finding was the poor reporting and potential biases arising from study design that limited reliable interpretation of the reported diagnostic accuracy. New reporting standards which address specific challenges of deep learning could improve future studies, enabling greater confidence in the results of future evaluations of this promising technology.Funding Statement: The authors state: "None"Declaration of Interests: All authors have completed the ICMJE uniform disclosure form online (available on request from the corresponding author) and declare: no support from any organization for the submitted work; no financial relationships with any organizations that might have an interest in the submitted work in the previous three years; no other relationships or activities that could appear to have influenced the submitted work.Ethics Approval Statement: The authors state: "Not required." The authors utilized PRISMA and MOOSE protocols.},
	language = {en},
	number = {ID 3384923},
	urldate = {2021-10-29},
	institution = {Social Science Research Network},
	author = {Faes, Livia and Liu, Xiaoxuan and Kale, Aditya and Bruynseels, Alice and Shamdas, Mohith and Moraes, Gabriella and Fu, Dun Jack and Wagner, Siegfried K. and Kern, Christoph and Ledsam, Joseph R. E. and Schmid, Martin K. and Topol, Eric J. and Balaskas, Konstantinos and Bachmann, Lucas M. and Keane, Pearse A. and Denniston, Alastair},
	month = may,
	year = {2019},
	keywords = {Artificial intelligence, classification, deep learning, diagnosis, diagnostic accuracy, machine learning, medical imaging, meta-analysis, sensitivity, specificity, systematic review},
	file = {(Liu et al., 2018).pdf:/Users/anne/Zotero/storage/9UTWIZDW/(Liu et al., 2018).pdf:application/pdf},
}

@article{shi_etal20,
	title = {A clinically applicable deep-learning model for detecting intracranial aneurysm in computed tomography angiography images},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-19527-w},
	doi = {10.1038/s41467-020-19527-w},
	abstract = {Intracranial aneurysm is a common life-threatening disease. Computed tomography angiography is recommended as the standard diagnosis tool; yet, interpretation can be time-consuming and challenging. We present a specific deep-learning-based model trained on 1,177 digital subtraction angiography verified bone-removal computed tomography angiography cases. The model has good tolerance to image quality and is tested with different manufacturers. Simulated real-world studies are conducted in consecutive internal and external cohorts, in which it achieves an improved patient-level sensitivity and lesion-level sensitivity compared to that of radiologists and expert neurosurgeons. A specific cohort of suspected acute ischemic stroke is employed and it is found that 99.0\% predicted-negative cases can be trusted with high confidence, leading to a potential reduction in human workload. A prospective study is warranted to determine whether the algorithm could improve patients’ care in comparison to clinicians’ assessment.},
	language = {en},
	number = {1},
	urldate = {2021-10-25},
	journal = {Nature Communications},
	author = {Shi, Zhao and Miao, Chongchang and Schoepf, U. Joseph and Savage, Rock H. and Dargis, Danielle M. and Pan, Chengwei and Chai, Xue and Li, Xiu Li and Xia, Shuang and Zhang, Xin and Gu, Yan and Zhang, Yonggang and Hu, Bin and Xu, Wenda and Zhou, Changsheng and Luo, Song and Wang, Hao and Mao, Li and Liang, Kongming and Wen, Lili and Zhou, Longjiang and Yu, Yizhou and Lu, Guang Ming and Zhang, Long Jiang},
	month = nov,
	year = {2020},
	pages = {6090},
	file = {(Shi et al., 2020).pdf:/Users/anne/Zotero/storage/J382RUF3/(Shi et al., 2020).pdf:application/pdf},
}

@article{rao_etal21,
	title = {Utility of {Artificial} {Intelligence} {Tool} as a {Prospective} {Radiology} {Peer} {Reviewer} — {Detection} of {Unreported} {Intracranial} {Hemorrhage}},
	volume = {28},
	issn = {10766332},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1076633220300842},
	doi = {10.1016/j.acra.2020.01.035},
	language = {en},
	number = {1},
	urldate = {2021-10-23},
	journal = {Academic Radiology},
	author = {Rao, Balaji and Zohrabian, Vahe and Cedeno, Paul and Saha, Atin and Pahade, Jay and Davis, Melissa A.},
	month = jan,
	year = {2021},
	keywords = {Artificial intelligence, Intracranial hemorrhage},
	pages = {85--93},
	file = {(Rao et al., 2021).pdf:/Users/anne/Zotero/storage/9HA6678M/(Rao et al., 2021).pdf:application/pdf},
}

@article{kim_etal21,
	title = {Cerebral hemorrhage detection and localization with medical imaging for cerebrovascular disease diagnosis and treatment using explainable deep learning},
	volume = {79},
	issn = {1976-8524},
	url = {https://doi.org/10.1007/s40042-021-00202-2},
	doi = {10.1007/s40042-021-00202-2},
	abstract = {Cerebral hemorrhages require rapid diagnosis and intensive treatment. This study aimed to detect cerebral hemorrhages and their locations in images using a deep learning model applying explainable deep learning. Normal brain images with no hemorrhages and images with subarachnoid, intraventricular, subdural, epidural, and intraparenchymal hemorrhages according to computed tomography (CT) (n = 200) were analyzed. A ResNet deep learning model, including image processing, was utilized. The visual explanation from a heatmap was made at the hemorrhage location using a gradient-class activation map (Grad-CAM). To evaluate the performance of the deep learning system, the accuracy, sensitivity, and specificity were determined. A hemorrhage prediction system for images of normal brains and brains with subarachnoid, intraventricular, subdural, epidural, and intraparenchymal hemorrhages was built. The Grad-CAM representation indicated the location of the hemorrhages in these images. In the prediction results, accurate predictions of the hemorrhage areas were made and visualizations of the corresponding locations overlapped in the images within (− 4, 1) pixel difference. The evaluation of the system performance showed an accuracy of 0.81 with a sensitivity of 0.67 and specificity of 0.86. These results constitue a proof of concept for the use of explainable artificial intelligence (XAI) to detect cerebral hemorrhages and visualize their locations in medical images, which will allow rapid diagnosis and treatment.},
	language = {en},
	number = {3},
	urldate = {2021-10-23},
	journal = {Journal of the Korean Physical Society},
	author = {Kim, Kwang Hyeon and Koo, Hae-Won and Lee, Byung-Jou and Yoon, Sang-Won and Sohn, Moon-Jun},
	month = aug,
	year = {2021},
	keywords = {Cerebral hemorrhage prediction, Cerebrovascular disease, Explainable artifcial intelligence},
	pages = {321--327},
	file = {(Kim et al., 2021).pdf:/Users/anne/Zotero/storage/VDZTNS3K/(Kim et al., 2021).pdf:application/pdf},
}

@article{gruschwitz_etal21,
	title = {Performance testing of a novel deep learning algorithm for the detection of intracranial hemorrhage and first trial under clinical conditions},
	volume = {1},
	issn = {27725286},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2772528621000054},
	doi = {10.1016/j.neuri.2021.100005},
	language = {en},
	number = {1-2},
	urldate = {2021-10-23},
	journal = {Neuroscience Informatics},
	author = {Gruschwitz, Philipp and Grunz, Jan-Peter and Kuhl, Philipp Josef and Kosmala, Aleksander and Bley, Thorsten Alexander and Petritsch, Bernhard and Heidenreich, Julius Frederik},
	month = sep,
	year = {2021},
	keywords = {Artificial intelligence, Intracranial hemorrhage, Computed tomography},
	pages = {100005},
	file = {(Gruschwitz et al. 2021).pdf:/Users/anne/Zotero/storage/4955ADQ8/(Gruschwitz et al. 2021).pdf:application/pdf},
}

@article{watanabe_etal21,
	title = {Improvement of the diagnostic accuracy for intracranial haemorrhage using deep learning–based computer-assisted detection},
	volume = {63},
	issn = {1432-1920},
	url = {https://doi.org/10.1007/s00234-020-02566-x},
	doi = {10.1007/s00234-020-02566-x},
	abstract = {To elucidate the effect of deep learning–based computer-assisted detection (CAD) on the performance of different-level physicians in detecting intracranial haemorrhage using CT.},
	language = {en},
	number = {5},
	urldate = {2021-10-22},
	journal = {Neuroradiology},
	author = {Watanabe, Yoshiyuki and Tanaka, Takahiro and Nishida, Atsushi and Takahashi, Hiroto and Fujiwara, Masahiro and Fujiwara, Takuya and Arisawa, Atsuko and Yano, Hiroki and Tomiyama, Noriyuki and Nakamura, Hajime and Todo, Kenichi and Yoshiya, Kazuhisa},
	month = may,
	year = {2021},
	keywords = {Computed tomography, Deep learning, Diagnosis, Efficacy, Intracranial haemorrhage, Retrospective},
	pages = {713--720},
	file = {(Watanabe et al., 2021).pdf:/Users/anne/Zotero/storage/PZAB5CTR/(Watanabe et al., 2021).pdf:application/pdf},
}

@article{dyer_etal21,
	title = {Validation of an artificial intelligence solution for acute triage and rule-out normal of non-contrast {CT} head scans},
	issn = {1432-1920},
	url = {https://doi.org/10.1007/s00234-021-02826-4},
	doi = {10.1007/s00234-021-02826-4},
	abstract = {Non-contrast CT head scans provide rapid and accurate diagnosis of acute head injury; however, increased utilisation of CT head scans makes it difficult to prioritise acutely unwell patients and places pressure on busy emergency departments (EDs). This study validates an AI algorithm to triage patients presenting with Intracranial Haemorrhage (ICH) or Acute Infarct whilst also identifying a subset of patients as Normal, with the potential to function as a rule-out test.},
	language = {en},
	urldate = {2021-10-22},
	journal = {Neuroradiology},
	author = {Dyer, Tom and Chawda, Sanjiv and Alkilani, Raed and Morgan, Tom Naunton and Hughes, Mike and Rasalingham, Simon},
	month = oct,
	year = {2021},
	keywords = {AI, CT head, Diagnostic, Rule-out normal},
	file = {(Dyer et al., 2021).pdf:/Users/anne/Zotero/storage/5VH8T9I2/(Dyer et al., 2021).pdf:application/pdf},
}

@article{dyer_etal21a,
	title = {Validation of an artificial intelligence solution for acute triage and rule-out normal of non-contrast {CT} head scans},
	issn = {1432-1920},
	url = {https://doi.org/10.1007/s00234-021-02826-4},
	doi = {10.1007/s00234-021-02826-4},
	abstract = {Non-contrast CT head scans provide rapid and accurate diagnosis of acute head injury; however, increased utilisation of CT head scans makes it difficult to prioritise acutely unwell patients and places pressure on busy emergency departments (EDs). This study validates an AI algorithm to triage patients presenting with Intracranial Haemorrhage (ICH) or Acute Infarct whilst also identifying a subset of patients as Normal, with the potential to function as a rule-out test.},
	journal = {Neuroradiology},
	author = {Dyer, Tom and Chawda, Sanjiv and Alkilani, Raed and Morgan, Tom Naunton and Hughes, Mike and Rasalingham, Simon},
	month = oct,
	year = {2021},
}

@article{gaube_etal21,
	title = {Do as {AI} say: {Susceptibility} in deployment of clinical decision-aids},
	volume = {4},
	issn = {2398-6352},
	url = {https://doi.org/10.1038/s41746-021-00385-9},
	doi = {10.1038/s41746-021-00385-9},
	abstract = {Artificial intelligence (AI) models for decision support have been developed for clinical settings such as radiology, but little work evaluates the potential impact of such systems. In this study, physicians received chest X-rays and diagnostic advice, some of which was inaccurate, and were asked to evaluate advice quality and make diagnoses. All advice was generated by human experts, but some was labeled as coming from an AI system. As a group, radiologists rated advice as lower quality when it appeared to come from an AI system; physicians with less task-expertise did not. Diagnostic accuracy was significantly worse when participants received inaccurate advice, regardless of the purported source. This work raises important considerations for how advice, AI and non-AI, should be deployed in clinical environments.},
	number = {31},
	journal = {npj Digital Medicine},
	author = {Gaube, Susanne and Suresh, Harini and Raue, Martina and Merritt, Alexander and Berkowitz, Seth J. and Lermer, Eva and Coughlin, Joseph F. and Guttag, John V. and Colak, Errol and Ghassemi, Marzyeh},
	month = feb,
	year = {2021},
	keywords = {artificial intelligence, decision support systems, generalizability, intracranial hemorrhage, noncontrast head CT},
	file = {(Gaube et al., 2021).pdf:/Users/anne/Zotero/storage/W9G9IRV7/(Gaube et al., 2021).pdf:application/pdf},
}

@article{voter_etal21,
	title = {Diagnostic {Accuracy} and {Failure} {Mode} {Analysis} of a {Deep} {Learning} {Algorithm} for the {Detection} of {Intracranial} {Hemorrhage}},
	volume = {18},
	issn = {15461440},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1546144021002271},
	doi = {10.1016/j.jacr.2021.03.005},
	language = {en},
	number = {8},
	urldate = {2021-10-22},
	journal = {Journal of the American College of Radiology},
	author = {Voter, Andrew F. and Meram, Ece and Garrett, John W. and Yu, John-Paul J.},
	month = aug,
	year = {2021},
	pages = {1143--1152},
	file = {(Voter et al. 2021).pdf:/Users/anne/Zotero/storage/DWFWZM9M/(Voter et al. 2021).pdf:application/pdf},
}

@article{merkin_etal22,
	title = {Machine learning, artificial intelligence and the prediction of dementia},
	volume = {35},
	issn = {0951-7367, 1473-6578},
	url = {https://journals.lww.com/10.1097/YCO.0000000000000768},
	doi = {10.1097/YCO.0000000000000768},
	language = {en},
	number = {2},
	urldate = {2022-06-22},
	journal = {Current Opinion in Psychiatry},
	author = {Merkin, Alexander and Krishnamurthi, Rita and Medvedev, Oleg N.},
	month = mar,
	year = {2022},
	pages = {123--129},
}

@misc{Artificial,
	title = {Artificial {Intelligence} for {Mental} {Health} and {Mental} {Illnesses}: an {Overview} {\textbar} {SpringerLink}},
	url = {https://link.springer.com/article/10.1007/s11920-019-1094-0},
	urldate = {2022-06-22},
	file = {Artificial Intelligence for Mental Health and Mental Illnesses\: an Overview | SpringerLink:/Users/anne/Zotero/storage/JLV6L3VC/s11920-019-1094-0.html:text/html},
}

@article{graham_etal19,
	title = {Artificial {Intelligence} for {Mental} {Health} and {Mental} {Illnesses}: an {Overview}},
	volume = {21},
	issn = {1535-1645},
	url = {https://doi.org/10.1007/s11920-019-1094-0},
	doi = {10.1007/s11920-019-1094-0},
	abstract = {Artificial intelligence (AI) technology holds both great promise to transform mental healthcare and potential pitfalls. This article provides an overview of AI and current applications in healthcare, a review of recent original research on AI specific to mental health, and a discussion of how AI can supplement clinical practice while considering its current limitations, areas needing additional research, and ethical implications regarding AI technology.},
	number = {11},
	journal = {Current Psychiatry Reports},
	author = {Graham, Sarah and Depp, Colin and Lee, Ellen E. and Nebeker, Camille and Tu, Xin and Kim, Ho-Cheol and Jeste, Dilip V.},
	month = nov,
	year = {2019},
	pages = {116},
}

@article{dalfonso_etal17,
	title = {Artificial {Intelligence}-{Assisted} {Online} {Social} {Therapy} for {Youth} {Mental} {Health}},
	volume = {8},
	issn = {1664-1078},
	url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2017.00796/full},
	doi = {10.3389/fpsyg.2017.00796},
	urldate = {2022-06-23},
	journal = {Frontiers in Psychology},
	author = {D'Alfonso, Simon and Santesteban-Echarri, Olga and Rice, Simon and Wadley, Greg and Lederman, Reeva and Miles, Christopher and Gleeson, John and Alvarez-Jimenez, Mario},
	month = jun,
	year = {2017},
	pages = {796},
	file = {Full Text:/Users/anne/Zotero/storage/XN87LVNM/D'Alfonso et al. - 2017 - Artificial Intelligence-Assisted Online Social The.pdf:application/pdf},
}

@article{rahman_etal20,
	title = {Application of {Machine} {Learning} {Methods} in {Mental} {Health} {Detection}: {A} {Systematic} {Review}},
	volume = {8},
	issn = {2169-3536},
	shorttitle = {Application of {Machine} {Learning} {Methods} in {Mental} {Health} {Detection}},
	url = {https://ieeexplore.ieee.org/document/9214815/},
	doi = {10.1109/ACCESS.2020.3029154},
	urldate = {2022-06-23},
	journal = {IEEE Access},
	author = {Rahman, Rohizah Abd and Omar, Khairuddin and Mohd Noah, Shahrul Azman and Danuri, Mohd Shahrul Nizam Mohd and Al-Garadi, Mohammed Ali},
	year = {2020},
	pages = {183952--183964},
	file = {Full Text:/Users/anne/Zotero/storage/ZGLAFDPC/Rahman et al. - 2020 - Application of Machine Learning Methods in Mental .pdf:application/pdf},
}

@article{lee_etal21,
	title = {Artificial {Intelligence} for {Mental} {Health} {Care}: {Clinical} {Applications}, {Barriers}, {Facilitators}, and {Artificial} {Wisdom}},
	volume = {6},
	issn = {24519022},
	shorttitle = {Artificial {Intelligence} for {Mental} {Health} {Care}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S245190222100046X},
	doi = {10.1016/j.bpsc.2021.02.001},
	language = {en},
	number = {9},
	urldate = {2022-06-23},
	journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
	author = {Lee, Ellen E. and Torous, John and De Choudhury, Munmun and Depp, Colin A. and Graham, Sarah A. and Kim, Ho-Cheol and Paulus, Martin P. and Krystal, John H. and Jeste, Dilip V.},
	month = sep,
	year = {2021},
	pages = {856--864},
	file = {Full Text:/Users/anne/Zotero/storage/6VQSWKNI/Lee et al. - 2021 - Artificial Intelligence for Mental Health Care Cl.pdf:application/pdf},
}

@article{Path20,
	title = {A {Path} for {Translation} of {Machine} {Learning} {Products} into {Healthcare} {Delivery}},
	issn = {2513-8634},
	url = {https://www.emjreviews.com/innovations/article/a-path-for-translation-of-machine-learning-products-into-healthcare-delivery/},
	doi = {10.33590/emjinnov/19-00172},
	abstract = {Despite enormous enthusiasm, machine learning models are rarely translated into clinical care and there is minimal evidence of clinical or economic impact. New conference venues and academic journals have emerged to promote the proliferating research; however, the translational path remains
unclear. This review undertakes the first in-depth study to identify how machine learning models that ingest structured electronic health record data can be applied to clinical decision support tasks and translated into clinical practice. The authors complement their own work with the experience of 21 machine learning products that address problems across clinical domains and across geographic populations. Four phases of translation emerge: design and develop, evaluate and validate, diffuse and scale, and continuing monitoring and maintenance. The review highlights the varying approaches taken across each phase by teams building machine learning products and presents a discussion of challenges and opportunities. The translational path and associated findings are instructive to researchers and developers building machine learning products, policy makers regulating machine learning products, and health system leaders who are considering adopting a machine learning product.},
	language = {en},
	urldate = {2022-06-23},
	journal = {EMJ Innovations},
	month = jan,
	year = {2020},
	file = {Full Text:/Users/anne/Zotero/storage/FVJ6IXMD/2020 - A Path for Translation of Machine Learning Product.pdf:application/pdf},
}

@article{habli_etal20,
	title = {Artificial intelligence in health care: accountability and safety},
	volume = {98},
	issn = {1564-0604},
	url = {https://pubmed.ncbi.nlm.nih.gov/32284648},
	doi = {10.2471/BLT.19.237487},
	abstract = {The prospect of patient harm caused by the decisions made by an artificial intelligence-based clinical tool is something to which current practices of accountability and safety worldwide have not yet adjusted. We focus on two aspects of clinical artificial intelligence used for decision-making: moral accountability for harm to patients; and safety assurance to protect patients against such harm. Artificial intelligence-based tools are challenging the standard clinical practices of assigning blame and assuring safety. Human clinicians and safety engineers have weaker control over the decisions reached by artificial intelligence systems and less knowledge and understanding of precisely how the artificial intelligence systems reach their decisions. We illustrate this analysis by applying it to an example of an artificial intelligence-based system developed for use in the treatment of sepsis. The paper ends with practical suggestions for ways forward to mitigate these concerns. We argue for a need to include artificial intelligence developers and systems safety engineers in our assessments of moral accountability for patient harm. Meanwhile, none of the actors in the model robustly fulfil the traditional conditions of moral accountability for the decisions of an artificial intelligence system. We should therefore update our conceptions of moral accountability in this context. We also need to move from a static to a dynamic model of assurance, accepting that considerations of safety are not fully resolvable during the design of the artificial intelligence system before the system has been deployed.},
	language = {eng},
	number = {4},
	journal = {Bulletin of the World Health Organization},
	author = {Habli, Ibrahim and Lawton, Tom and Porter, Zoe},
	month = apr,
	year = {2020},
	note = {Edition: 2020/02/25
Publisher: World Health Organization},
	keywords = {*Artificial Intelligence, *Delivery of Health Care, *Safety Management, *Social Responsibility, Health Facilities},
	pages = {251--256},
	file = {Habli et al. - 2020 - Artificial intelligence in health care accountabi.pdf:/Users/anne/Zotero/storage/7PHBVGSW/Habli et al. - 2020 - Artificial intelligence in health care accountabi.pdf:application/pdf},
}

@article{kelly_etal19,
	title = {Key challenges for delivering clinical impact with artificial intelligence},
	volume = {17},
	issn = {1741-7015},
	url = {https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-019-1426-2},
	doi = {10.1186/s12916-019-1426-2},
	abstract = {Abstract
            
              Background
              Artificial intelligence (AI) research in healthcare is accelerating rapidly, with potential applications being demonstrated across various domains of medicine. However, there are currently limited examples of such techniques being successfully deployed into clinical practice. This article explores the main challenges and limitations of AI in healthcare, and considers the steps required to translate these potentially transformative technologies from research to clinical practice.
            
            
              Main body
              Key challenges for the translation of AI systems in healthcare include those intrinsic to the science of machine learning, logistical difficulties in implementation, and consideration of the barriers to adoption as well as of the necessary sociocultural or pathway changes. Robust peer-reviewed clinical evaluation as part of randomised controlled trials should be viewed as the gold standard for evidence generation, but conducting these in practice may not always be appropriate or feasible. Performance metrics should aim to capture real clinical applicability and be understandable to intended users. Regulation that balances the pace of innovation with the potential for harm, alongside thoughtful post-market surveillance, is required to ensure that patients are not exposed to dangerous interventions nor deprived of access to beneficial innovations. Mechanisms to enable direct comparisons of AI systems must be developed, including the use of independent, local and representative test sets. Developers of AI algorithms must be vigilant to potential dangers, including dataset shift, accidental fitting of confounders, unintended discriminatory bias, the challenges of generalisation to new populations, and the unintended negative consequences of new algorithms on health outcomes.
            
            
              Conclusion
              The safe and timely translation of AI research into clinically validated and appropriately regulated systems that can benefit everyone is challenging. Robust clinical evaluation, using metrics that are intuitive to clinicians and ideally go beyond measures of technical accuracy to include quality of care and patient outcomes, is essential. Further work is required (1) to identify themes of algorithmic bias and unfairness while developing mitigations to address these, (2) to reduce brittleness and improve generalisability, and (3) to develop methods for improved interpretability of machine learning predictions. If these goals can be achieved, the benefits for patients are likely to be transformational.},
	language = {en},
	number = {1},
	urldate = {2022-06-23},
	journal = {BMC Medicine},
	author = {Kelly, Christopher J. and Karthikesalingam, Alan and Suleyman, Mustafa and Corrado, Greg and King, Dominic},
	month = dec,
	year = {2019},
	pages = {195},
	file = {Full Text:/Users/anne/Zotero/storage/N7QL96EP/Kelly et al. - 2019 - Key challenges for delivering clinical impact with.pdf:application/pdf},
}

@article{chekroud_krystal15,
	title = {Personalised pharmacotherapy: an interim solution for antidepressant treatment?},
	volume = {350},
	issn = {1756-1833},
	shorttitle = {Personalised pharmacotherapy},
	url = {https://www.bmj.com/lookup/doi/10.1136/bmj.h2502},
	doi = {10.1136/bmj.h2502},
	language = {en},
	number = {may14 13},
	urldate = {2022-06-23},
	journal = {BMJ},
	author = {Chekroud, A. M. and Krystal, J. H.},
	month = may,
	year = {2015},
	pages = {h2502--h2502},
}

@article{chekroud_etal16,
	title = {Cross-trial prediction of treatment outcome in depression: a machine learning approach},
	volume = {3},
	issn = {22150366},
	shorttitle = {Cross-trial prediction of treatment outcome in depression},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S221503661500471X},
	doi = {10.1016/S2215-0366(15)00471-X},
	language = {en},
	number = {3},
	urldate = {2022-06-23},
	journal = {The Lancet Psychiatry},
	author = {Chekroud, Adam Mourad and Zotti, Ryan Joseph and Shehzad, Zarrar and Gueorguieva, Ralitza and Johnson, Marcia K and Trivedi, Madhukar H and Cannon, Tyrone D and Krystal, John Harrison and Corlett, Philip Robert},
	month = mar,
	year = {2016},
	pages = {243--250},
}

@article{chekroud_etal17,
	title = {Reevaluating the {Efficacy} and {Predictability} of {Antidepressant} {Treatments}: {A} {Symptom} {Clustering} {Approach}},
	volume = {74},
	issn = {2168-622X},
	shorttitle = {Reevaluating the {Efficacy} and {Predictability} of {Antidepressant} {Treatments}},
	url = {http://archpsyc.jamanetwork.com/article.aspx?doi=10.1001/jamapsychiatry.2017.0025},
	doi = {10.1001/jamapsychiatry.2017.0025},
	language = {en},
	number = {4},
	urldate = {2022-06-23},
	journal = {JAMA Psychiatry},
	author = {Chekroud, Adam M. and Gueorguieva, Ralitza and Krumholz, Harlan M. and Trivedi, Madhukar H. and Krystal, John H. and McCarthy, Gregory},
	month = apr,
	year = {2017},
	pages = {370},
}

@article{megerian_etal22,
	title = {Evaluation of an artificial intelligence-based medical device for diagnosis of autism spectrum disorder},
	volume = {5},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-022-00598-6},
	doi = {10.1038/s41746-022-00598-6},
	abstract = {Abstract
            Autism spectrum disorder (ASD) can be reliably diagnosed at 18 months, yet significant diagnostic delays persist in the United States. This double-blinded, multi-site, prospective, active comparator cohort study tested the accuracy of an artificial intelligence-based Software as a Medical Device designed to aid primary care healthcare providers (HCPs) in diagnosing ASD. The Device combines behavioral features from three distinct inputs (a caregiver questionnaire, analysis of two short home videos, and an HCP questionnaire) in a gradient boosted decision tree machine learning algorithm to produce either an ASD positive, ASD negative, or indeterminate output. This study compared Device outputs to diagnostic agreement by two or more independent specialists in a cohort of 18–72-month-olds with developmental delay concerns (425 study completers, 36\% female, 29\% ASD prevalence). Device output PPV for all study completers was 80.8\% (95\% confidence intervals (CI), 70.3\%–88.8\%) and NPV was 98.3\% (90.6\%–100\%). For the 31.8\% of participants who received a determinate output (ASD positive or negative) Device sensitivity was 98.4\% (91.6\%–100\%) and specificity was 78.9\% (67.6\%–87.7\%). The Device’s indeterminate output acts as a risk control measure when inputs are insufficiently granular to make a determinate recommendation with confidence. If this risk control measure were removed, the sensitivity for all study completers would fall to 51.6\% (63/122) (95\% CI 42.4\%, 60.8\%), and specificity would fall to 18.5\% (56/303) (95\% CI 14.3\%, 23.3\%). Among participants for whom the Device abstained from providing a result, specialists identified that 91\% had one or more complex neurodevelopmental disorders. No significant differences in Device performance were found across participants’ sex, race/ethnicity, income, or education level. For nearly a third of this primary care sample, the Device enabled timely diagnostic evaluation with a high degree of accuracy. The Device shows promise to significantly increase the number of children able to be diagnosed with ASD in a primary care setting, potentially facilitating earlier intervention and more efficient use of specialist resources.},
	language = {en},
	number = {1},
	urldate = {2022-06-28},
	journal = {npj Digital Medicine},
	author = {Megerian, Jonathan T. and Dey, Sangeeta and Melmed, Raun D. and Coury, Daniel L. and Lerner, Marc and Nicholls, Christopher J. and Sohl, Kristin and Rouhbakhsh, Rambod and Narasimhan, Anandhi and Romain, Jonathan and Golla, Sailaja and Shareef, Safiullah and Ostrovsky, Andrey and Shannon, Jennifer and Kraft, Colleen and Liu-Mayo, Stuart and Abbas, Halim and Gal-Szabo, Diana E. and Wall, Dennis P. and Taraman, Sharief},
	month = dec,
	year = {2022},
	pages = {57},
	file = {Full Text:/Users/anne/Zotero/storage/GNYNUBM2/Megerian et al. - 2022 - Evaluation of an artificial intelligence-based med.pdf:application/pdf},
}

@misc{https,
	title = {https://www.youtube.com/watch?v={MigeWoptzrQ}},
}

@article{chekroud_etal16a,
	title = {Cross-trial prediction of treatment outcome in depression: a machine learning approach},
	volume = {3},
	issn = {22150366},
	shorttitle = {Cross-trial prediction of treatment outcome in depression},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S221503661500471X},
	doi = {10.1016/S2215-0366(15)00471-X},
	language = {en},
	number = {3},
	urldate = {2022-06-28},
	journal = {The Lancet Psychiatry},
	author = {Chekroud, Adam Mourad and Zotti, Ryan Joseph and Shehzad, Zarrar and Gueorguieva, Ralitza and Johnson, Marcia K and Trivedi, Madhukar H and Cannon, Tyrone D and Krystal, John Harrison and Corlett, Philip Robert},
	month = mar,
	year = {2016},
	pages = {243--250},
}

@article{delgadillo_etal18,
	title = {Feedback-informed treatment versus usual psychological treatment for depression and anxiety: a multisite, open-label, cluster randomised controlled trial},
	volume = {5},
	issn = {22150366},
	shorttitle = {Feedback-informed treatment versus usual psychological treatment for depression and anxiety},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2215036618301627},
	doi = {10.1016/S2215-0366(18)30162-7},
	language = {en},
	number = {7},
	urldate = {2022-06-28},
	journal = {The Lancet Psychiatry},
	author = {Delgadillo, Jaime and de Jong, Kim and Lucock, Mike and Lutz, Wolfgang and Rubel, Julian and Gilbody, Simon and Ali, Shehzad and Aguirre, Elisa and Appleton, Mark and Nevin, Jacqueline and O'Hayon, Harry and Patel, Ushma and Sainty, Andrew and Spencer, Peter and McMillan, Dean},
	month = jul,
	year = {2018},
	pages = {564--572},
	file = {Full Text:/Users/anne/Zotero/storage/XFHEDWRN/Delgadillo et al. - 2018 - Feedback-informed treatment versus usual psycholog.pdf:application/pdf},
}

@article{chekroud_etal21,
	title = {The promise of machine learning in predicting treatment outcomes in psychiatry},
	volume = {20},
	issn = {2051-5545},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wps.20882},
	doi = {10.1002/wps.20882},
	abstract = {For many years, psychiatrists have tried to understand factors involved in response to medications or psychotherapies, in order to personalize their treatment choices. There is now a broad and growing interest in the idea that we can develop models to personalize treatment decisions using new statistical approaches from the field of machine learning and applying them to larger volumes of data. In this pursuit, there has been a paradigm shift away from experimental studies to confirm or refute specific hypotheses towards a focus on the overall explanatory power of a predictive model when tested on new, unseen datasets. In this paper, we review key studies using machine learning to predict treatment outcomes in psychiatry, ranging from medications and psychotherapies to digital interventions and neurobiological treatments. Next, we focus on some new sources of data that are being used for the development of predictive models based on machine learning, such as electronic health records, smartphone and social media data, and on the potential utility of data from genetics, electrophysiology, neuroimaging and cognitive testing. Finally, we discuss how far the field has come towards implementing prediction tools in real-world clinical practice. Relatively few retrospective studies to-date include appropriate external validation procedures, and there are even fewer prospective studies testing the clinical feasibility and effectiveness of predictive models. Applications of machine learning in psychiatry face some of the same ethical challenges posed by these techniques in other areas of medicine or computer science, which we discuss here. In short, machine learning is a nascent but important approach to improve the effectiveness of mental health care, and several prospective clinical studies suggest that it may be working already.},
	language = {en},
	number = {2},
	urldate = {2022-06-29},
	journal = {World Psychiatry},
	author = {Chekroud, Adam M. and Bondar, Julia and Delgadillo, Jaime and Doherty, Gavin and Wasil, Akash and Fokkema, Marjolein and Cohen, Zachary and Belgrave, Danielle and DeRubeis, Robert and Iniesta, Raquel and Dwyer, Dominic and Choi, Karmel},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wps.20882},
	keywords = {Computational psychiatry, electronic health records, external validation, machine learning, pharmacotherapies, prediction, psy­chotherapies, smartphone data, treatment outcomes},
	pages = {154--170},
	annote = {Implementation challenges

},
	file = {World Psychiatry - 2021 - Chekroud - The promise of machine learning in predicting treatment outcomes in psychiatry.pdf:/Users/anne/Zotero/storage/6LNF43I2/World Psychiatry - 2021 - Chekroud - The promise of machine learning in predicting treatment outcomes in psychiatry.pdf:application/pdf},
}

@article{aafjes-vandoorn_etal21,
	title = {A scoping review of machine learning in psychotherapy research},
	volume = {31},
	issn = {1050-3307, 1468-4381},
	url = {https://www.tandfonline.com/doi/full/10.1080/10503307.2020.1808729},
	doi = {10.1080/10503307.2020.1808729},
	abstract = {Machine learning (ML) offers robust statistical and probabilistic techniques that can help to make sense of large amounts of data. This scoping review paper aims to broadly explore the nature of research activity using ML in the context of psychological talk therapies, highlighting the scope of current methods and considerations for clinical practice and directions for future research. Using a systematic search methodology, fifty-one studies were identified. A narrative synthesis indicates two types of studies, those who developed and tested an ML model (k=44), and those who reported on the feasibility of a particular treatment tool that uses an ML algorithm (k=7). Most model development studies used supervised learning techniques to classify or predict labeled treatment process or outcome data, whereas others used unsupervised techniques to identify clusters in the unlabeled patient or treatment data. Overall, the current applications of ML in psychotherapy research demonstrated a range of possible benefits for indications of treatment process, adherence, therapist skills and treatment response prediction, as well as ways to accelerate research through automated behavioral or linguistic process coding. Given the novelty and potential of this research field, these proof-of-concept studies are encouraging, however, do not necessarily translate to improved clinical practice (yet).},
	language = {en},
	number = {1},
	urldate = {2022-06-29},
	journal = {Psychotherapy Research},
	author = {Aafjes-van Doorn, Katie and Kamsteeg, Céline and Bate, Jordan and Aafjes, Marc},
	month = jan,
	year = {2021},
	pages = {92--116},
	annote = {Implementation issues and opportunities 


(practitioner training?)



},
	file = {A scoping review of machine learning in psychotherapy research.pdf:/Users/anne/Zotero/storage/7PMHJXVD/A scoping review of machine learning in psychotherapy research.pdf:application/pdf},
}

@article{shatte_etal19,
	title = {Machine learning in mental health: a scoping review of methods and applications},
	volume = {49},
	issn = {0033-2917, 1469-8978},
	shorttitle = {Machine learning in mental health},
	url = {https://www.cambridge.org/core/journals/psychological-medicine/article/abs/machine-learning-in-mental-health-a-scoping-review-of-methods-and-applications/0B70B1C827B3A4604C1C01026049F7D9},
	doi = {10.1017/S0033291719000151},
	abstract = {BackgroundThis paper aims to synthesise the literature on machine learning (ML) and big data applications for mental health, highlighting current research and applications in practice.MethodsWe employed a scoping review methodology to rapidly map the field of ML in mental health. Eight health and information technology research databases were searched for papers covering this domain. Articles were assessed by two reviewers, and data were extracted on the article's mental health application, ML technique, data type, and study results. Articles were then synthesised via narrative review.ResultsThree hundred papers focusing on the application of ML to mental health were identified. Four main application domains emerged in the literature, including: (i) detection and diagnosis; (ii) prognosis, treatment and support; (iii) public health, and; (iv) research and clinical administration. The most common mental health conditions addressed included depression, schizophrenia, and Alzheimer's disease. ML techniques used included support vector machines, decision trees, neural networks, latent Dirichlet allocation, and clustering.ConclusionsOverall, the application of ML to mental health has demonstrated a range of benefits across the areas of diagnosis, treatment and support, research, and clinical administration. With the majority of studies identified focusing on the detection and diagnosis of mental health conditions, it is evident that there is significant room for the application of ML to other areas of psychology and mental health. The challenges of using ML techniques are discussed, as well as opportunities to improve and advance the field.},
	language = {en},
	number = {9},
	urldate = {2022-06-29},
	journal = {Psychological Medicine},
	author = {Shatte, Adrian B. R. and Hutchinson, Delyse M. and Teague, Samantha J.},
	month = jul,
	year = {2019},
	note = {Publisher: Cambridge University Press},
	keywords = {Big data, health informatics, machine learning, mental health},
	pages = {1426--1448},
	file = {Submitted Version:/Users/anne/Zotero/storage/9D3NTKHZ/Shatte et al. - 2019 - Machine learning in mental health a scoping revie.pdf:application/pdf},
}
